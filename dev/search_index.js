var documenterSearchIndex = {"docs":
[{"location":"","page":"Home","title":"Home","text":"CurrentModule = MLNanoShaper","category":"page"},{"location":"#MLNanoShaper","page":"Home","title":"MLNanoShaper","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for MLNanoShaper.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modules = [MLNanoShaper]","category":"page"},{"location":"#MLNanoShaper.AccumulatorLogger","page":"Home","title":"MLNanoShaper.AccumulatorLogger","text":"accumulator(processing,logger)\n\nA processing logger that transform logger on multiple batches Ca be used to liss numerical data, for logging to TensorBoardLogger.\n\n\n\n\n\n","category":"type"},{"location":"#MLNanoShaper.Auxiliary_parameters","page":"Home","title":"MLNanoShaper.Auxiliary_parameters","text":"Auxiliary_parameters\n\nThe variables that do not influence the outome of the training run. This include the nb_epoch.\n\n\n\n\n\n","category":"type"},{"location":"#MLNanoShaper.TrainingData","page":"Home","title":"MLNanoShaper.TrainingData","text":"Training information used in model training.\n\nFields\n\natoms: the set of atoms used as model input\nskin : the Surface generated by Nanoshaper\n\n\n\n\n\n","category":"type"},{"location":"#MLNanoShaper.Training_parameters","page":"Home","title":"MLNanoShaper.Training_parameters","text":"Training_parameters\n\nThe training parameters used in the model training. Default values are in the param file. The training is deterministric. Theses values are hased to determine a training run\n\n\n\n\n\n","category":"type"},{"location":"#MLNanoShaper.categorical_loss-Tuple{Any, Any, Any, StructArrays.StructVector{@NamedTuple{point::GeometryBasics.Point{3, Float32}, input::StructArrays.StructArray{MLNanoShaperRunner.PreprocessData{Float32}}, d_real::Float32}}}","page":"Home","title":"MLNanoShaper.categorical_loss","text":"categorical_loss(model, ps, st, (; point, atoms, d_real))\n\nThe loss function used by in training. Return the KL divergence between true probability and empirical probability Return the error with the espected distance as a metric.\n\n\n\n\n\n","category":"method"},{"location":"#MLNanoShaper.comonicon_install-Tuple{}","page":"Home","title":"MLNanoShaper.comonicon_install","text":"comonicon_install(;kwargs...)\n\nInstall the CLI manually. This will use the default configuration in Comonicon.toml, if it exists. For more detailed reference, please refer to Comonicon documentation.\n\n\n\n\n\n","category":"method"},{"location":"#MLNanoShaper.comonicon_install_path-Tuple{}","page":"Home","title":"MLNanoShaper.comonicon_install_path","text":"comonicon_install_path(;[yes=false])\n\nInstall the PATH and FPATH to your shell configuration file. You can use comonicon_install_path(;yes=true) to skip interactive prompt. For more detailed reference, please refer to Comonicon documentation.\n\n\n\n\n\n","category":"method"},{"location":"#MLNanoShaper.continus_loss-Tuple{Any, Any, Any, StructArrays.StructVector{@NamedTuple{point::GeometryBasics.Point{3, Float32}, input::StructArrays.StructArray{MLNanoShaperRunner.PreprocessData{Float32}}, d_real::Float32}}}","page":"Home","title":"MLNanoShaper.continus_loss","text":"continus_loss(model, ps, st, (; point, atoms, d_real))\n\nThe loss function used by in training. compare the predicted (square) distance with frac1 + \tanh(d)2 Return the error with the espected distance as a metric.\n\n\n\n\n\n","category":"method"},{"location":"#MLNanoShaper.evaluate_model-Tuple{Lux.StatefulLuxLayer, GeometryBasics.Point{3, Float32}, MLNanoShaperRunner.AnnotedKDTree}","page":"Home","title":"MLNanoShaper.evaluate_model","text":"evaluate_model(\n    model::Lux.StatefulLuxLayer, x::Point3f, atoms::AnnotedKDTree; cutoff_radius, default_value = -0.0f0)\n\nevaluate the model on a single point.\nThis function handle the logic in case the point is too far from the atoms. In this case default_value is returned and the model is not run.\n\n\n\n\n\n","category":"method"},{"location":"#MLNanoShaper.generate_data-Tuple{}","page":"Home","title":"MLNanoShaper.generate_data","text":"generate_data()\n\ngenerate data from the parameters files in param/ by downloading the pdb files and running Nanoshaper. \n\n\n\n\n\n","category":"method"},{"location":"#MLNanoShaper.implicit_surface-Union{Tuple{T}, Tuple{MLNanoShaperRunner.AnnotedKDTree{GeometryBasics.Sphere{T}, :center, GeometryBasics.Point3{T}}, Lux.StatefulLuxLayer, Any}} where T","page":"Home","title":"MLNanoShaper.implicit_surface","text":"implicit_surface(atoms::AnnotedKDTree{Sphere{T}, :center, Point3{T}},\n    model::Lux.StatefulLuxLayer, (;\n        cutoff_radius, step)) where {T}\n\nCreate a mesh form the isosurface of function `pos -> model(atoms,pos)` using marching cubes algorithm and using step size `step`.\n\n\n\n\n\n","category":"method"},{"location":"#MLNanoShaper.load_data_pdb-Tuple{Type{<:Number}, String}","page":"Home","title":"MLNanoShaper.load_data_pdb","text":"load_data_pdb(T, name::String)\n\nLoad a TrainingData{T} from current directory. You should have a pdb and an off file with name name in current directory.\n\n\n\n\n\n","category":"method"},{"location":"#MLNanoShaper.load_data_pqr-Tuple{Type{<:Number}, String}","page":"Home","title":"MLNanoShaper.load_data_pqr","text":"load_data_pqr(T, name::String)\n\nLoad a TrainingData{T} from current directory. You should have a pdb and an off file with name name in current directory.\n\n\n\n\n\n","category":"method"},{"location":"#MLNanoShaper.train","page":"Home","title":"MLNanoShaper.train","text":"train [options] [flags]\n\nTrain a model.\n\nIntro\n\nParameters are specified in the param/param.toml file. The folowing parameters can be overided.\n\nOptions\n\n--nb-epoch, -e <Int>: the number of epoch to compute.\n--model, -m <String>: the model name. Can be anakin.\n--nb-data-points, -d <Int>: the number of proteins in the dataset to use\n--name, -n <String>: name of the training run\n--cutoff-radius, -c <Float32>: the cutoff_radius used in training\n--ref-distance, -d <Float32>: the reference distane (in A) used to rescale distance to surface in loss\n\nFlags\n\n--gpu, -g: should we do the training on the gpu\n--categorical, -c: should we use the categorical version of the model\n\n\n\n\n\n","category":"function"},{"location":"#MLNanoShaper.train-Tuple{MLNanoShaper.Training_parameters, MLNanoShaper.Auxiliary_parameters}","page":"Home","title":"MLNanoShaper.train","text":"train(training_parameters::Training_parameters, directories::Auxiliary_parameters)\n\ntrain the model given Training_parameters and Auxiliary_parameters.\n\n\n\n\n\n","category":"method"},{"location":"#MLNanoShaper.train-Tuple{Tuple{MLUtils.AbstractDataContainer, MLUtils.AbstractDataContainer}, Lux.Experimental.TrainState, MLNanoShaper.Training_parameters, MLNanoShaper.Auxiliary_parameters}","page":"Home","title":"MLNanoShaper.train","text":"train((train_data,test_data),training_states; nb_epoch)\n\ntrain the model on the data with nb_epoch\n\n\n\n\n\n","category":"method"}]
}
